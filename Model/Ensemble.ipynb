{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "outer-drink",
   "metadata": {},
   "source": [
    "# Creating an Ensemble Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-mozambique",
   "metadata": {},
   "source": [
    "## Installs and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-dragon",
   "metadata": {},
   "source": [
    "### Install all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "optimum-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment line below to install all required libraries\n",
    "# !pip3 install -r ../requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-irish",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adapted-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cutting-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.initializers import constant\n",
    "from keras.optimizers import Adam\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-dominican",
   "metadata": {},
   "source": [
    "## Load cleaned tweets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "frozen-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./cleaned_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "preliminary-entry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>Porter_Stem</th>\n",
       "      <th>Snowball_Stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>aww bummer shoulda got david carr third day</td>\n",
       "      <td>aww bummer shoulda got david carr third day</td>\n",
       "      <td>aww bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset cannot update facebook texting might cry...</td>\n",
       "      <td>upset can not updat facebook text might cri re...</td>\n",
       "      <td>upset can not updat facebook text might cri re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>dived many times ball managed save rest go bounds</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>behaving im mad cannot see</td>\n",
       "      <td>behav im mad can not see</td>\n",
       "      <td>behav im mad can not see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1          0  is upset that he can't update his Facebook by ...   \n",
       "2          0  @Kenichan I dived many times for the ball. Man...   \n",
       "3          0    my whole body feels itchy and like its on fire    \n",
       "4          0  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                       cleaned_tweet  \\\n",
       "0        aww bummer shoulda got david carr third day   \n",
       "1  upset cannot update facebook texting might cry...   \n",
       "2  dived many times ball managed save rest go bounds   \n",
       "3                   whole body feels itchy like fire   \n",
       "4                         behaving im mad cannot see   \n",
       "\n",
       "                                         Porter_Stem  \\\n",
       "0        aww bummer shoulda got david carr third day   \n",
       "1  upset can not updat facebook text might cri re...   \n",
       "2       dive mani time ball manag save rest go bound   \n",
       "3                    whole bodi feel itchi like fire   \n",
       "4                           behav im mad can not see   \n",
       "\n",
       "                                       Snowball_Stem  \n",
       "0        aww bummer shoulda got david carr third day  \n",
       "1  upset can not updat facebook text might cri re...  \n",
       "2       dive mani time ball manag save rest go bound  \n",
       "3                    whole bodi feel itchi like fire  \n",
       "4                           behav im mad can not see  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(450)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-teens",
   "metadata": {},
   "source": [
    "## Drop text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deluxe-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['sentiment', 'Snowball_Stem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "imposed-stack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Snowball_Stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>aww bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>upset can not updat facebook text might cri re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>behav im mad can not see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                      Snowball_Stem\n",
       "0          0        aww bummer shoulda got david carr third day\n",
       "1          0  upset can not updat facebook text might cri re...\n",
       "2          0       dive mani time ball manag save rest go bound\n",
       "3          0                    whole bodi feel itchi like fire\n",
       "4          0                           behav im mad can not see"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-oxford",
   "metadata": {},
   "source": [
    "## Drop rows with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "waiting-permission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment           0\n",
       "Snowball_Stem    8046\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "seventh-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dominant-czech",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment        0\n",
       "Snowball_Stem    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-quebec",
   "metadata": {},
   "source": [
    "# 5. Reduce dataframe size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dense-explosion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(795860, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment != 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "retired-operation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(796094, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "continuing-metallic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment != 0][:200000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "distinguished-explorer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 0][:200000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "infectious-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = pd.concat([df[df.sentiment != 0][740000:], df[df.sentiment == 0][740000:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "painted-concert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111954, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "loved-thirty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "under-dakota",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Snowball_Stem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "valuable-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "arabic-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "absent-output",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397989,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-cycle",
   "metadata": {},
   "source": [
    "## Loading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "infinite-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_path = './SVM_UnigramBigram_75.pickle'\n",
    "nb_path = './NB_UnigramBigram_78.pickle'\n",
    "lstm_token_path = './LSTM_tokenizer.pickle'\n",
    "lstm_path = './LSTM_train_75_val_78_test_79_acc.h5'\n",
    "vectorizer_path = './UnigramBigram_vectorizer.pickle'\n",
    "RF_path = './RFC_UnigramBigram_72.pickle'\n",
    "Blstm_path ='./B_LSTM_train_76_26_val_77_86_test_78_57_acc.h5'\n",
    "blstm_token_path = './BLSTM_tokenizer.pickle'\n",
    "# DT_path = 'DT_72.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "appreciated-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = pickle.load(open(svm_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "collectible-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = pickle.load(open(nb_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "latest-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = pickle.load(open(lstm_token_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "corresponding-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = keras.models.load_model(lstm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "interracial-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = pickle.load(open(blstm_token_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "earned-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open(vectorizer_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "every-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = pickle.load(open(RF_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "lightweight-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "Blstm = keras.models.load_model(Blstm_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-little",
   "metadata": {},
   "source": [
    "# Encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "federal-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "y_test = Encoder.fit_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-tennis",
   "metadata": {},
   "source": [
    "## Running the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "scheduled-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-hospital",
   "metadata": {},
   "source": [
    "### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "institutional-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB3 = nb.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "double-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_acc = accuracy_score(NB3, y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "widespread-standard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.87652422554392"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-trinity",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "unique-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_pred = svm.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "meaning-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_acc = accuracy_score(SVM_pred, y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "appropriate-cholesterol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.36997756219392"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-priority",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "provincial-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "broken-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "southwest-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet_pad = pad_sequences(test_tweet_seq, maxlen=max_seq_length, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "novel-democrat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   8,  582,  356,   28,  239,   80, 3031,    8,   32,   38,  279,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweet_pad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "secure-stage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 582, 356, 28, 239, 80, 3031, 8, 32, 38, 279]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweet_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "desperate-lindsay",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = lstm.predict(test_tweet_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "jewish-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_pred =[]\n",
    "for i in lstm_pred:\n",
    "    a = float(i)\n",
    "    if a>=0.5:\n",
    "        a = 1\n",
    "    else:\n",
    "        a = 0\n",
    "    LSTM_pred.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "guided-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_pred = np.array(LSTM_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "burning-publication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.1798265781215"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_acc = accuracy_score(LSTM_pred, y_test)*100\n",
    "lstm_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "foreign-germany",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12438/12438 [==============================] - 18s 1ms/step - loss: 0.4445 - accuracy: 0.7918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.44447553157806396, 0.7917982935905457]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = lstm.evaluate(test_tweet_pad, y_test)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-supervisor",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "statistical-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_pred = RF.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "mental-single",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.10654314566483"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_acc = accuracy_score(RF_pred, y_test)*100\n",
    "RF_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-palestinian",
   "metadata": {},
   "source": [
    "## Bi Directional Lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "activated-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "equal-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttweet_seq = token.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "marine-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttweet_pad = pad_sequences(ttweet_seq, maxlen=seq_length, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "educational-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLSTM_pred = Blstm.predict(ttweet_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "hundred-composition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 20)            3587280   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 64)                13568     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,600,913\n",
      "Trainable params: 3,600,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Blstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "remarkable-booth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12438/12438 [==============================] - 28s 2ms/step - loss: 0.4533 - accuracy: 0.7864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4532645642757416, 0.7863935828208923]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = Blstm.evaluate(ttweet_pad, y_test)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "painted-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "Blstm_pred =[]\n",
    "for i in BLSTM_pred:\n",
    "    a = float(i)\n",
    "    if a>=0.5:\n",
    "        a = 1\n",
    "    else:\n",
    "        a = 0\n",
    "    Blstm_pred.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "substantial-california",
   "metadata": {},
   "outputs": [],
   "source": [
    "Blstm_pred = np.array(Blstm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "extraordinary-overview",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.63935937927933"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Blstm_acc = accuracy_score(Blstm_pred, y_test)*100\n",
    "Blstm_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-blood",
   "metadata": {},
   "source": [
    "## Putting predictions in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "included-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame(y_test,columns=['Expected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "stuffed-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf['SVM Predictions'] = SVM_pred\n",
    "pdf['NB Predictions'] = NB3\n",
    "pdf['LSTM Predictions'] = LSTM_pred\n",
    "pdf['BLSTM Predictions'] = Blstm_pred\n",
    "#pdf['Decision Tree Predictions'] = DT_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "comfortable-smell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expected</th>\n",
       "      <th>SVM Predictions</th>\n",
       "      <th>NB Predictions</th>\n",
       "      <th>LSTM Predictions</th>\n",
       "      <th>BLSTM Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Expected  SVM Predictions  NB Predictions  LSTM Predictions  \\\n",
       "1         1                1               1                 1   \n",
       "2         0                0               1                 1   \n",
       "\n",
       "   BLSTM Predictions  \n",
       "1                  1  \n",
       "2                  1  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.head()[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "personalized-allah",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.1798265781215"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-fence",
   "metadata": {},
   "source": [
    "### Ensemble func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ideal-chuck",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.24713656140170648,\n",
       " 0.2487545817826636,\n",
       " 0.25291761338783453,\n",
       " 0.2511912434277955]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deno = (NB_acc + SVM_acc+ lstm_acc + Blstm_acc)\n",
    "wNB = NB_acc/deno\n",
    "wSVM = SVM_acc/deno\n",
    "wLSTM = lstm_acc/deno\n",
    "wBLSTM = Blstm_acc/deno\n",
    "# wDT = DT_acc/deno\n",
    "classWeights = [wSVM, wNB, wLSTM, wBLSTM]\n",
    "classWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "sophisticated-navigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(a):\n",
    "    pc = 0\n",
    "    nc = 0\n",
    "    for i in a:\n",
    "        if i == 'Expected':\n",
    "            continue\n",
    "        if int(a[i]) ==1:\n",
    "            pc+=1\n",
    "        else:\n",
    "            nc+=1\n",
    "            \n",
    "    p_pc = pc/(pc+nc)\n",
    "    p_nc = 1-p_pc\n",
    "    pscore =0\n",
    "    nscore =0\n",
    "    for w in classWeights:\n",
    "        pscore+=w*pc\n",
    "        nscore+=w*nc\n",
    "    \n",
    "    if pscore>=nscore:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "asian-orbit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397989"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = len(pdf)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "latin-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensPred = []\n",
    "for i in range(l):\n",
    "    ensPred.append(ensemble_predict(pdf[i:i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "early-convergence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.50119224400675"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ensPred, y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "minor-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_weighted_pred = pdf['SVM Predictions']*classWeights[0]\n",
    "nb_weighted_pred = pdf['NB Predictions']*classWeights[1]\n",
    "lstm_weighted_pred = pdf['LSTM Predictions']*classWeights[2]\n",
    "blstm_weighted_pred = pdf['BLSTM Predictions']*classWeights[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "rental-hearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_pred_sum = svm_weighted_pred + nb_weighted_pred + lstm_weighted_pred + blstm_weighted_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "appropriate-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf['Ensemble_predictions'] = list(map(lambda x: 1 if x>=0.5 else 0, weighted_pred_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "colored-mountain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.50119224400675"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pdf['Ensemble_predictions'],y_test)*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
