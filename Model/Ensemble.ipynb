{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "verbal-pollution",
   "metadata": {},
   "source": [
    "# Creating an Ensemble Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-picture",
   "metadata": {},
   "source": [
    "## Installs and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-civilization",
   "metadata": {},
   "source": [
    "### Install all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment line below to install all required libraries\n",
    "# !pip3 install -r ../requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-perth",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "effective-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "marine-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.initializers import constant\n",
    "from keras.optimizers import Adam\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-renewal",
   "metadata": {},
   "source": [
    "## Load cleaned tweets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "democratic-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./cleaned_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "considerable-education",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>Porter_Stem</th>\n",
       "      <th>Snowball_Stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>awww thats bummer shoulda got david carr third...</td>\n",
       "      <td>awww that bummer shoulda got david carr third day</td>\n",
       "      <td>awww that bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset cant update facebook texting might cry r...</td>\n",
       "      <td>upset cant updat facebook text might cri resul...</td>\n",
       "      <td>upset cant updat facebook text might cri resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>dived many times ball managed save rest go bounds</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>behaving im mad cant see</td>\n",
       "      <td>behav im mad cant see</td>\n",
       "      <td>behav im mad cant see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1          0  is upset that he can't update his Facebook by ...   \n",
       "2          0  @Kenichan I dived many times for the ball. Man...   \n",
       "3          0    my whole body feels itchy and like its on fire    \n",
       "4          0  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                       cleaned_tweet  \\\n",
       "0  awww thats bummer shoulda got david carr third...   \n",
       "1  upset cant update facebook texting might cry r...   \n",
       "2  dived many times ball managed save rest go bounds   \n",
       "3                   whole body feels itchy like fire   \n",
       "4                           behaving im mad cant see   \n",
       "\n",
       "                                         Porter_Stem  \\\n",
       "0  awww that bummer shoulda got david carr third day   \n",
       "1  upset cant updat facebook text might cri resul...   \n",
       "2       dive mani time ball manag save rest go bound   \n",
       "3                    whole bodi feel itchi like fire   \n",
       "4                              behav im mad cant see   \n",
       "\n",
       "                                       Snowball_Stem  \n",
       "0  awww that bummer shoulda got david carr third day  \n",
       "1  upset cant updat facebook text might cri resul...  \n",
       "2       dive mani time ball manag save rest go bound  \n",
       "3                    whole bodi feel itchi like fire  \n",
       "4                              behav im mad cant see  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(450)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-pointer",
   "metadata": {},
   "source": [
    "## Drop text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "likely-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['sentiment', 'Snowball_Stem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "proprietary-moment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Snowball_Stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>awww that bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>upset cant updat facebook text might cri resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>behav im mad cant see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                      Snowball_Stem\n",
       "0          0  awww that bummer shoulda got david carr third day\n",
       "1          0  upset cant updat facebook text might cri resul...\n",
       "2          0       dive mani time ball manag save rest go bound\n",
       "3          0                    whole bodi feel itchi like fire\n",
       "4          0                              behav im mad cant see"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-original",
   "metadata": {},
   "source": [
    "## Drop rows with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "creative-immunology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment           0\n",
       "Snowball_Stem    7661\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caring-collapse",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "touched-reverse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment        0\n",
       "Snowball_Stem    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-pierre",
   "metadata": {},
   "source": [
    "# 5. Reduce dataframe size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "regular-artist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(796018, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment != 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "engaging-ordinary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(796321, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "excess-ecology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment != 0][:200000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "heavy-beijing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 0][:200000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "prospective-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = pd.concat([df[df.sentiment != 0][740000:], df[df.sentiment == 0][740000:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "american-craps",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112339, 2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "attempted-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "adjusted-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Snowball_Stem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "combined-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "rocky-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= reduced_df['Snowball_Stem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "innovative-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = reduced_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "facial-sailing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1543744    strang introduc boyfriend vladimir despit name...\n",
       "1543745    get follow day use www tweeterfollow com add e...\n",
       "1543746                  look forward russel visit next week\n",
       "1543747       im time life well ok show need go come back nc\n",
       "1543748                               im realli realli happi\n",
       "Name: Snowball_Stem, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "interpreted-hungary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1543744    1\n",
       "1543745    1\n",
       "1543746    1\n",
       "1543747    1\n",
       "1543748    1\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-fourth",
   "metadata": {},
   "source": [
    "## Loading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "raised-notice",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_path = './SVM_UnigramBigram_75.pickle'\n",
    "nb_path = './NB_UnigramBigram_78.pickle'\n",
    "lstm_path = './LSTM_train_79_val_76_test_74_acc.h5'\n",
    "vectorizer_path = './UnigramBigram_vectorizer.pickle'\n",
    "RF_path = './RFC_UnigramBigram.pickle'\n",
    "DT_path = 'DT_72.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "latin-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = pickle.load(open(svm_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dependent-latest",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = pickle.load(open(nb_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "stainless-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm = keras.models.load_model(lstm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "twelve-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open(vectorizer_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "enormous-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = pickle.load(open(RF_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "listed-macro",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = pickle.load(open(DT_path,'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-commander",
   "metadata": {},
   "source": [
    "# Encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "organized-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "y_test = Encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-wisdom",
   "metadata": {},
   "source": [
    "## Running the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-release",
   "metadata": {},
   "source": [
    "### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "casual-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "failing-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB3 = nb.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "significant-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_acc = accuracy_score(NB3, y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "grateful-internet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.68227418794898"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-indie",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "reverse-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_pred = svm.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "hawaiian-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_acc = accuracy_score(SVM_pred, y_test)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-declaration",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of all unique words\n",
    "\n",
    "def count_unique_words(tweets):\n",
    "    unique = Counter()\n",
    "    for tweet in tweets:\n",
    "        for word in tweet.split():\n",
    "            unique[word] += 1\n",
    "    return unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = count_unique_words(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=len(word_count))\n",
    "tokenizer.fit_on_texts(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet_pad = pad_sequences(test_tweet_seq, maxlen=max_seq_length, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet_pad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = lstm.predict(test_tweet_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-facial",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_pred =[]\n",
    "for i in lstm_pred:\n",
    "    a = float(i)\n",
    "    if a>=0.5:\n",
    "        a = 1\n",
    "    else:\n",
    "        a = 0\n",
    "    LSTM_pred.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_pred = np.array(LSTM_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_acc = accuracy_score(LSTM_pred, y_test)\n",
    "lstm_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = lstm.evaluate(test_tweet_pad, y_test)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-engagement",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "endangered-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_pred = RF.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "figured-major",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.23260844408442"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_acc = accuracy_score(RF_pred, y_test)*100\n",
    "RF_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-canon",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "thrown-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_pred = DT.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "confused-berkeley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112339"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DT_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "united-abortion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.14146467388886"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_acc = accuracy_score(DT_pred, y_test)*100\n",
    "DT_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-ghost",
   "metadata": {},
   "source": [
    "## Putting predictions in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "nonprofit-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame(y_test,columns=['Expected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "congressional-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf['SVM Predictions'] = SVM_pred\n",
    "pdf['Naive Bayes Predictions'] = NB3\n",
    "#pdf['LSTM Predictions'] = LSTM_pred\n",
    "#pdf['Random Forest Predictions'] = RF_pred\n",
    "pdf['Decision Tree Predictions'] = DT_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "champion-oasis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expected</th>\n",
       "      <th>SVM Predictions</th>\n",
       "      <th>Naive Bayes Predictions</th>\n",
       "      <th>Decision Tree Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Expected  SVM Predictions  Naive Bayes Predictions  \\\n",
       "1         1                1                        1   \n",
       "2         1                1                        1   \n",
       "\n",
       "   Decision Tree Predictions  \n",
       "1                          1  \n",
       "2                          0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.head()[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-upset",
   "metadata": {},
   "source": [
    "### Ensemble func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "comfortable-compact",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.28262781349315763,\n",
       " 0.24990059353640307,\n",
       " 0.23225413226138822,\n",
       " 0.2352174607090511]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deno = (NB_acc + SVM_acc+RF_acc + DT_acc)\n",
    "wNB = NB_acc/deno\n",
    "wSVM = SVM_acc/deno\n",
    "#wLSTM = lstm_acc/deno\n",
    "wRF = RF_acc/deno\n",
    "wDT = DT_acc/deno\n",
    "classWeights = [wNB, wSVM,wRF, wDT]\n",
    "classWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "continued-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(a):\n",
    "    pc = 0\n",
    "    nc = 0\n",
    "    for i in a:\n",
    "        if i == 'Expected':\n",
    "            continue\n",
    "        if int(a[i]) ==1:\n",
    "            pc+=1\n",
    "        else:\n",
    "            nc+=1\n",
    "            \n",
    "    p_pc = pc/(pc+nc)\n",
    "    p_nc = 1-p_pc\n",
    "    pscore =0\n",
    "    nscore =0\n",
    "    for w in classWeights:\n",
    "        pscore+=w*pc\n",
    "        nscore+=w*nc\n",
    "    \n",
    "    if pscore>nscore:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "overall-secret",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = len(pdf)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fresh-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensPred = []\n",
    "for i in range(l):\n",
    "    ensPred.append(ensemble_predict(pdf[i:i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "unique-communication",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [100000, 112339]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-741552103823>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensPred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [100000, 112339]"
     ]
    }
   ],
   "source": [
    "accuracy_score(ensPred, y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-bangkok",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
