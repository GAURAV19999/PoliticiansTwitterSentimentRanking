{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "centered-trailer",
   "metadata": {},
   "source": [
    "# Creating an Ensemble Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-bernard",
   "metadata": {},
   "source": [
    "## Installs and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-diagram",
   "metadata": {},
   "source": [
    "### Install all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "interpreted-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment line below to install all required libraries\n",
    "# !pip3 install -r ../requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-competition",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thorough-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "funky-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.initializers import constant\n",
    "from keras.optimizers import Adam\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-diesel",
   "metadata": {},
   "source": [
    "## Load cleaned tweets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "impressive-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./cleaned_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "speaking-words",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>Porter_Stem</th>\n",
       "      <th>Snowball_Stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>awww thats bummer shoulda got david carr third...</td>\n",
       "      <td>awww that bummer shoulda got david carr third day</td>\n",
       "      <td>awww that bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset cant update facebook texting might cry r...</td>\n",
       "      <td>upset cant updat facebook text might cri resul...</td>\n",
       "      <td>upset cant updat facebook text might cri resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>dived many times ball managed save rest go bounds</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>behaving im mad cant see</td>\n",
       "      <td>behav im mad cant see</td>\n",
       "      <td>behav im mad cant see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1          0  is upset that he can't update his Facebook by ...   \n",
       "2          0  @Kenichan I dived many times for the ball. Man...   \n",
       "3          0    my whole body feels itchy and like its on fire    \n",
       "4          0  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                       cleaned_tweet  \\\n",
       "0  awww thats bummer shoulda got david carr third...   \n",
       "1  upset cant update facebook texting might cry r...   \n",
       "2  dived many times ball managed save rest go bounds   \n",
       "3                   whole body feels itchy like fire   \n",
       "4                           behaving im mad cant see   \n",
       "\n",
       "                                         Porter_Stem  \\\n",
       "0  awww that bummer shoulda got david carr third day   \n",
       "1  upset cant updat facebook text might cri resul...   \n",
       "2       dive mani time ball manag save rest go bound   \n",
       "3                    whole bodi feel itchi like fire   \n",
       "4                              behav im mad cant see   \n",
       "\n",
       "                                       Snowball_Stem  \n",
       "0  awww that bummer shoulda got david carr third day  \n",
       "1  upset cant updat facebook text might cri resul...  \n",
       "2       dive mani time ball manag save rest go bound  \n",
       "3                    whole bodi feel itchi like fire  \n",
       "4                              behav im mad cant see  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(450)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-venice",
   "metadata": {},
   "source": [
    "## Drop text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "devoted-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['sentiment', 'Snowball_Stem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sweet-german",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Snowball_Stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>awww that bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>upset cant updat facebook text might cri resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>behav im mad cant see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                      Snowball_Stem\n",
       "0          0  awww that bummer shoulda got david carr third day\n",
       "1          0  upset cant updat facebook text might cri resul...\n",
       "2          0       dive mani time ball manag save rest go bound\n",
       "3          0                    whole bodi feel itchi like fire\n",
       "4          0                              behav im mad cant see"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-playlist",
   "metadata": {},
   "source": [
    "## Drop rows with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "patient-polish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment           0\n",
       "Snowball_Stem    7661\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "manual-initial",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cognitive-oasis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment        0\n",
       "Snowball_Stem    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-alert",
   "metadata": {},
   "source": [
    "# 5. Reduce dataframe size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acute-spread",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(796018, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment != 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "disturbed-vault",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(796321, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "parental-connection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment != 0][:200000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "metropolitan-manitoba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 0][:200000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "smart-klein",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = pd.concat([df[df.sentiment != 0][640000:690000], df[df.sentiment == 0][640000:690000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lasting-jesus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "accomplished-medicine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "rotary-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Snowball_Stem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "forbidden-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "departmental-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= reduced_df['Snowball_Stem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "widespread-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = reduced_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "stuffed-individual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1443331    haley like sing oreo mouth love nick love talk...\n",
       "1443332    love weekend famili make popcorn clean mess wo...\n",
       "1443333    world wrap orang ribbon sinc orang fave color ...\n",
       "1443334                            hahaha someth amus ploiis\n",
       "1443335    christiiiiin thanx homi ur town come tomorrow ...\n",
       "Name: Snowball_Stem, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "civilian-george",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1443331    1\n",
       "1443332    1\n",
       "1443333    1\n",
       "1443334    1\n",
       "1443335    1\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-going",
   "metadata": {},
   "source": [
    "## Loading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "found-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_path = './SVM_UnigramBigram_75.pickle'\n",
    "nb_path = './NB_UnigramBigram_78.pickle'\n",
    "lstm_path = './LSTM_train_79_val_76_test_74_acc.h5'\n",
    "vectorizer_path = './UnigramBigram_vectorizer.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "neutral-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = pickle.load(open(svm_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "radical-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = pickle.load(open(nb_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "variable-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = keras.models.load_model(lstm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "pointed-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open(vectorizer_path,'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-triangle",
   "metadata": {},
   "source": [
    "# Encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "proud-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "y_test = Encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-outside",
   "metadata": {},
   "source": [
    "## Running the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-briefing",
   "metadata": {},
   "source": [
    "### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "excited-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "brazilian-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB3 = nb.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "iraqi-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_acc = accuracy_score(NB3, y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "medium-intersection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.153"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-gathering",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "convenient-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_pred = svm.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "qualified-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_acc = accuracy_score(SVM_pred, y_test)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-brand",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "italic-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of all unique words\n",
    "\n",
    "def count_unique_words(tweets):\n",
    "    unique = Counter()\n",
    "    for tweet in tweets:\n",
    "        for word in tweet.split():\n",
    "            unique[word] += 1\n",
    "    return unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "impaired-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = count_unique_words(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "spectacular-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "roman-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=len(word_count))\n",
    "tokenizer.fit_on_texts(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "geological-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "comparable-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet_pad = pad_sequences(test_tweet_seq, maxlen=max_seq_length, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "organizational-burke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4424,     7,   482,  4029,  1102,     6,   746,     6,   122,\n",
       "       17303,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweet_pad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "golden-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = lstm.predict(test_tweet_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cooked-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_pred =[]\n",
    "for i in lstm_pred:\n",
    "    a = float(i)\n",
    "    if a>=0.5:\n",
    "        a = 1\n",
    "    else:\n",
    "        a = 0\n",
    "    LSTM_pred.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "statistical-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_pred = np.array(LSTM_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "conceptual-customs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50842"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_acc = accuracy_score(LSTM_pred, y_test)\n",
    "lstm_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "intended-pakistan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 11s 3ms/step - loss: 0.9449 - accuracy: 0.5084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9449368715286255, 0.5084199905395508]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = lstm.evaluate(test_tweet_pad, y_test)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-recipe",
   "metadata": {},
   "source": [
    "## Putting predictions in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "equivalent-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame(y_test,columns=['Expected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "recovered-scheme",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expected</th>\n",
       "      <th>SVM Predictions</th>\n",
       "      <th>Naive Bayes Predictions</th>\n",
       "      <th>LSTM Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Expected  SVM Predictions  Naive Bayes Predictions  LSTM Predictions\n",
       "1         1                1                        1                 0\n",
       "2         1                1                        1                 0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.head()[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "clinical-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf['SVM Predictions'] = SVM_pred\n",
    "pdf['Naive Bayes Predictions'] = NB3\n",
    "pdf['LSTM Predictions'] = LSTM_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-freeware",
   "metadata": {},
   "source": [
    "### Ensemble func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "enormous-wages",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.530967466796637, 0.469032533203363]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deno = (NB_acc + SVM_acc)\n",
    "wNB = NB_acc/deno\n",
    "wSVM = SVM_acc/deno\n",
    "wLSTM = lstm_acc/deno\n",
    "classWeights = [wNB, wSVM]\n",
    "classWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "moved-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(a):\n",
    "    pc = 0\n",
    "    nc = 0\n",
    "    for i in a:\n",
    "        if i == 'Expected':\n",
    "            continue\n",
    "        if int(a[i]) ==1:\n",
    "            pc+=1\n",
    "        else:\n",
    "            nc+=1\n",
    "            \n",
    "    p_pc = pc/(pc+nc)\n",
    "    p_nc = 1-p_pc\n",
    "    pscore =0\n",
    "    nscore =0\n",
    "    for w in classWeights:\n",
    "        pscore+=w*pc\n",
    "        nscore+=w*nc\n",
    "    \n",
    "    if pscore>nscore:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "hispanic-reader",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = len(pdf)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "exact-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensPred = []\n",
    "for i in range(l):\n",
    "    ensPred.append(ensemble_predict(pdf[i:i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "declared-basic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.094"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ensPred, y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-medicaid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
