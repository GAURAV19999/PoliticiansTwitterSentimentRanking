{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fluid-executive",
   "metadata": {},
   "source": [
    "# LSTM Model for classification of tweet sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-terminal",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-pasta",
   "metadata": {},
   "source": [
    "# 1. Installs and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-parcel",
   "metadata": {},
   "source": [
    "## 1.1. Install all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stuffed-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment line below to install all required libraries\n",
    "# !pip3 install -r ../requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-chemistry",
   "metadata": {},
   "source": [
    "## 1.2. Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "induced-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.initializers import constant\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-smell",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-version",
   "metadata": {},
   "source": [
    "# 2. Load cleaned tweets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "engaging-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/cleaned_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "suburban-instruction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>Porter_Stem</th>\n",
       "      <th>Snowball_Stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>aww bummer shoulda got david carr third day</td>\n",
       "      <td>aww bummer shoulda got david carr third day</td>\n",
       "      <td>aww bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset cannot update facebook texting might cry...</td>\n",
       "      <td>upset can not updat facebook text might cri re...</td>\n",
       "      <td>upset can not updat facebook text might cri re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>dived many times ball managed save rest go bounds</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>behaving im mad cannot see</td>\n",
       "      <td>behav im mad can not see</td>\n",
       "      <td>behav im mad can not see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1          0  is upset that he can't update his Facebook by ...   \n",
       "2          0  @Kenichan I dived many times for the ball. Man...   \n",
       "3          0    my whole body feels itchy and like its on fire    \n",
       "4          0  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                       cleaned_tweet  \\\n",
       "0        aww bummer shoulda got david carr third day   \n",
       "1  upset cannot update facebook texting might cry...   \n",
       "2  dived many times ball managed save rest go bounds   \n",
       "3                   whole body feels itchy like fire   \n",
       "4                         behaving im mad cannot see   \n",
       "\n",
       "                                         Porter_Stem  \\\n",
       "0        aww bummer shoulda got david carr third day   \n",
       "1  upset can not updat facebook text might cri re...   \n",
       "2       dive mani time ball manag save rest go bound   \n",
       "3                    whole bodi feel itchi like fire   \n",
       "4                           behav im mad can not see   \n",
       "\n",
       "                                       Snowball_Stem  \n",
       "0        aww bummer shoulda got david carr third day  \n",
       "1  upset can not updat facebook text might cri re...  \n",
       "2       dive mani time ball manag save rest go bound  \n",
       "3                    whole bodi feel itchi like fire  \n",
       "4                           behav im mad can not see  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-voltage",
   "metadata": {},
   "source": [
    "# 3. Drop text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "absent-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['sentiment', 'Snowball_Stem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reserved-sunglasses",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Snowball_Stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>aww bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>upset can not updat facebook text might cri re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>behav im mad can not see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                      Snowball_Stem\n",
       "0          0        aww bummer shoulda got david carr third day\n",
       "1          0  upset can not updat facebook text might cri re...\n",
       "2          0       dive mani time ball manag save rest go bound\n",
       "3          0                    whole bodi feel itchi like fire\n",
       "4          0                           behav im mad can not see"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-harassment",
   "metadata": {},
   "source": [
    "# 4. Drop rows with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "concrete-vietnam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment           0\n",
       "Snowball_Stem    8046\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "agreed-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "after-navigator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment        0\n",
       "Snowball_Stem    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-beach",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-maldives",
   "metadata": {},
   "source": [
    "# 5. Reduce dataframe size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adolescent-royalty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(795860, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment != 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "powerful-region",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(796094, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "reflected-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.sentiment != 0][:200000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "infrared-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.sentiment == 0][:200000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "suspected-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduced_df = pd.concat([df[df.sentiment != 0][:200000], df[df.sentiment == 0][:200000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "preceding-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduced_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "flying-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = reduced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-jason",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-carol",
   "metadata": {},
   "source": [
    "# 5. Split dataset into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "assumed-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Snowball_Stem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "reduced-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "breeding-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-beast",
   "metadata": {},
   "source": [
    "- 75% training data\n",
    "- 25% test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "marine-diameter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1193965,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "charming-fetish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1193965,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "tribal-tunisia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397989,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "structural-reviewer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397989,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-deployment",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-holly",
   "metadata": {},
   "source": [
    "# 6. Collection of all unique words in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "million-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of all unique words\n",
    "\n",
    "def count_unique_words(tweets):\n",
    "    unique = Counter()\n",
    "    for tweet in tweets:\n",
    "        for word in tweet.split():\n",
    "            unique[word] += 1\n",
    "    return unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "corrected-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = count_unique_words(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "northern-prize",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179702"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-conditioning",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-marshall",
   "metadata": {},
   "source": [
    "# 7. LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-panel",
   "metadata": {},
   "source": [
    "## 7.1. Max number of words in a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "specialized-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-parameter",
   "metadata": {},
   "source": [
    "## 7.2. Create / Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "pacific-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = Tokenizer(num_words=len(word_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "weighted-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./SavedModels/LSTM_tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-opinion",
   "metadata": {},
   "source": [
    "## 7.3. Tokenize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "stock-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "incident-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "convinced-premises",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203576"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index for each word in tokenizer\n",
    "len(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-azerbaijan",
   "metadata": {},
   "source": [
    "## 7.4. Convert training data to tokenized sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "funky-olive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'whole bodi feel itchi like fire'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "unlimited-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq = tokenizer.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "classical-nelson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[446, 1919, 303, 996, 283, 4421, 153, 4670, 4670, 33, 3798, 884]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_seq[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-action",
   "metadata": {},
   "source": [
    "## 7.5. Padding training sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "placed-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_seq_length, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "maritime-pontiac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 446, 1919,  303,  996,  283, 4421,  153, 4670, 4670,   33, 3798,\n",
       "        884,    0,    0,    0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-publication",
   "metadata": {},
   "source": [
    "## 7.6. Performing tokenization and padding for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "unusual-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "loose-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_seq_length, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-submission",
   "metadata": {},
   "source": [
    "## 7.7. Understanding training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "communist-investing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[240, 3204, 3204, 165, 396, 24, 532, 167]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "simple-refrigerator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 240, 3204, 3204,  165,  396,   24,  532,  167,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "arbitrary-skating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25, 13, 38]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "governing-terrain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25, 13, 38,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "changing-bishop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1193965, 20)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "tamil-charm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397989, 20)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "determined-cleaners",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1193965,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "military-reputation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397989,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-signal",
   "metadata": {},
   "source": [
    "## 7.8 Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "foreign-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Maps each word to a finite vector\n",
    "model.add(Embedding(len(word_count), 20, input_length=max_seq_length))\n",
    "\n",
    "model.add(LSTM(32, dropout=0.1))\n",
    "\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0003)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "serious-today",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 20, 20)            3594040   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                6784      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,600,857\n",
      "Trainable params: 3,600,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "joint-liverpool",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37312/37312 [==============================] - 1448s 39ms/step - loss: 0.4981 - accuracy: 0.7523 - val_loss: 0.4636 - val_accuracy: 0.7811\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_pad, y_train, epochs=1, validation_data=(X_test_pad, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-shell",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-peter",
   "metadata": {},
   "source": [
    "# 8. Evaluating model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-disco",
   "metadata": {},
   "source": [
    "## 8.1. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "unique-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./SavedModels/LSTM_train_75_val_78_test_79_acc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "consolidated-intervention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 20)            3586000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                6784      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,592,817\n",
      "Trainable params: 3,592,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-priest",
   "metadata": {},
   "source": [
    "## 8.2. Create test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bottom-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/cleaned_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mysterious-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.concat([test_df[test_df.sentiment != 0][:100000], test_df[test_df.sentiment == 0][:100000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "mental-motorcycle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>Porter_Stem</th>\n",
       "      <th>Snowball_Stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>aww bummer shoulda got david carr third day</td>\n",
       "      <td>aww bummer shoulda got david carr third day</td>\n",
       "      <td>aww bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset cannot update facebook texting might cry...</td>\n",
       "      <td>upset can not updat facebook text might cri re...</td>\n",
       "      <td>upset can not updat facebook text might cri re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>dived many times ball managed save rest go bounds</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>behaving im mad cannot see</td>\n",
       "      <td>behav im mad can not see</td>\n",
       "      <td>behav im mad can not see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1          0  is upset that he can't update his Facebook by ...   \n",
       "2          0  @Kenichan I dived many times for the ball. Man...   \n",
       "3          0    my whole body feels itchy and like its on fire    \n",
       "4          0  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                       cleaned_tweet  \\\n",
       "0        aww bummer shoulda got david carr third day   \n",
       "1  upset cannot update facebook texting might cry...   \n",
       "2  dived many times ball managed save rest go bounds   \n",
       "3                   whole body feels itchy like fire   \n",
       "4                         behaving im mad cannot see   \n",
       "\n",
       "                                         Porter_Stem  \\\n",
       "0        aww bummer shoulda got david carr third day   \n",
       "1  upset can not updat facebook text might cri re...   \n",
       "2       dive mani time ball manag save rest go bound   \n",
       "3                    whole bodi feel itchi like fire   \n",
       "4                           behav im mad can not see   \n",
       "\n",
       "                                       Snowball_Stem  \n",
       "0        aww bummer shoulda got david carr third day  \n",
       "1  upset can not updat facebook text might cri re...  \n",
       "2       dive mani time ball manag save rest go bound  \n",
       "3                    whole bodi feel itchi like fire  \n",
       "4                           behav im mad can not see  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dominican-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[['sentiment', 'Snowball_Stem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "theoretical-necessity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Snowball_Stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>aww bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>upset can not updat facebook text might cri re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>behav im mad can not see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                      Snowball_Stem\n",
       "0          0        aww bummer shoulda got david carr third day\n",
       "1          0  upset can not updat facebook text might cri re...\n",
       "2          0       dive mani time ball manag save rest go bound\n",
       "3          0                    whole bodi feel itchi like fire\n",
       "4          0                           behav im mad can not see"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-willow",
   "metadata": {},
   "source": [
    "## 8.3. Drop rows with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "better-colleague",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment           0\n",
       "Snowball_Stem    8046\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "indie-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "supreme-folks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment        0\n",
       "Snowball_Stem    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-chemical",
   "metadata": {},
   "source": [
    "## 8.4. Tokenization and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "latin-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet = test_df['Snowball_Stem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sunrise-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "after-demonstration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          aww bummer shoulda got david carr third day\n",
       "1    upset can not updat facebook text might cri re...\n",
       "2         dive mani time ball manag save rest go bound\n",
       "3                      whole bodi feel itchi like fire\n",
       "4                             behav im mad can not see\n",
       "Name: Snowball_Stem, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "streaming-nebraska",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sweet-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet_seq = tokenizer.texts_to_sequences(test_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "signal-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet_pad = pad_sequences(test_tweet_seq, maxlen=max_seq_length, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "tough-brighton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  98, 1014, 3008,   10,  696, 6269, 1600,    3,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweet_pad[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-matter",
   "metadata": {},
   "source": [
    "## 8.5. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "relative-irrigation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49749/49749 [==============================] - 113s 2ms/step - loss: 0.4451 - accuracy: 0.7912\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_tweet_pad, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "signal-filter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.44509533047676086, 0.791164219379425]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "falling-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ahead-government",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on test set: 0.44509533047676086\n",
      "Accuracy achieve on test set: 0.791164219379425\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss on test set:\", loss)\n",
    "print(\"Accuracy achieve on test set:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-visibility",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-dodge",
   "metadata": {},
   "source": [
    "# 9. Save model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "incorporated-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./SavedModels/LSTM_train_75_val_78_test_79_acc.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fitting-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./SavedModels/LSTM_tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
