{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fluid-executive",
   "metadata": {},
   "source": [
    "# LSTM Model for classification of tweet sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-terminal",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-pasta",
   "metadata": {},
   "source": [
    "# 1. Installs and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-parcel",
   "metadata": {},
   "source": [
    "## 1.1. Install all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stuffed-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment line below to install all required libraries\n",
    "# !pip3 install -r ../requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-chemistry",
   "metadata": {},
   "source": [
    "## 1.2. Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "induced-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.initializers import constant\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-smell",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-version",
   "metadata": {},
   "source": [
    "# 2. Load cleaned tweets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "engaging-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/cleaned_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "suburban-instruction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>Porter_Stem</th>\n",
       "      <th>Snowball_Stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>aww bummer shoulda got david carr third day</td>\n",
       "      <td>aww bummer shoulda got david carr third day</td>\n",
       "      <td>aww bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset cannot update facebook texting might cry...</td>\n",
       "      <td>upset can not updat facebook text might cri re...</td>\n",
       "      <td>upset can not updat facebook text might cri re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>dived many times ball managed save rest go bounds</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>behaving im mad cannot see</td>\n",
       "      <td>behav im mad can not see</td>\n",
       "      <td>behav im mad can not see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1          0  is upset that he can't update his Facebook by ...   \n",
       "2          0  @Kenichan I dived many times for the ball. Man...   \n",
       "3          0    my whole body feels itchy and like its on fire    \n",
       "4          0  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                       cleaned_tweet  \\\n",
       "0        aww bummer shoulda got david carr third day   \n",
       "1  upset cannot update facebook texting might cry...   \n",
       "2  dived many times ball managed save rest go bounds   \n",
       "3                   whole body feels itchy like fire   \n",
       "4                         behaving im mad cannot see   \n",
       "\n",
       "                                         Porter_Stem  \\\n",
       "0        aww bummer shoulda got david carr third day   \n",
       "1  upset can not updat facebook text might cri re...   \n",
       "2       dive mani time ball manag save rest go bound   \n",
       "3                    whole bodi feel itchi like fire   \n",
       "4                           behav im mad can not see   \n",
       "\n",
       "                                       Snowball_Stem  \n",
       "0        aww bummer shoulda got david carr third day  \n",
       "1  upset can not updat facebook text might cri re...  \n",
       "2       dive mani time ball manag save rest go bound  \n",
       "3                    whole bodi feel itchi like fire  \n",
       "4                           behav im mad can not see  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-voltage",
   "metadata": {},
   "source": [
    "# 3. Drop text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "absent-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['sentiment', 'Snowball_Stem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reserved-sunglasses",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Snowball_Stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>aww bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>upset can not updat facebook text might cri re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>behav im mad can not see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                      Snowball_Stem\n",
       "0          0        aww bummer shoulda got david carr third day\n",
       "1          0  upset can not updat facebook text might cri re...\n",
       "2          0       dive mani time ball manag save rest go bound\n",
       "3          0                    whole bodi feel itchi like fire\n",
       "4          0                           behav im mad can not see"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-harassment",
   "metadata": {},
   "source": [
    "# 4. Drop rows with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "concrete-vietnam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment           0\n",
       "Snowball_Stem    8046\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "agreed-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "after-navigator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment        0\n",
       "Snowball_Stem    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-beach",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-carol",
   "metadata": {},
   "source": [
    "# 5. Split dataset into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "assumed-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Snowball_Stem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "reduced-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "breeding-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-beast",
   "metadata": {},
   "source": [
    "- 80% training data\n",
    "- 20% test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "marine-diameter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1273563,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "charming-fetish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1273563,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "tribal-tunisia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318391,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "structural-reviewer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318391,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-deployment",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-holly",
   "metadata": {},
   "source": [
    "# 6. Collection of all unique words in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "million-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of all unique words\n",
    "\n",
    "def count_unique_words(tweets):\n",
    "    unique = Counter()\n",
    "    for tweet in tweets:\n",
    "        for word in tweet.split():\n",
    "            unique[word] += 1\n",
    "    return unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "corrected-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = count_unique_words(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "northern-prize",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186771"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding Vocabulary size\n",
    "len(word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-conditioning",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-marshall",
   "metadata": {},
   "source": [
    "# 7. LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-panel",
   "metadata": {},
   "source": [
    "## 7.1. Max number of words in a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "specialized-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-parameter",
   "metadata": {},
   "source": [
    "## 7.2. Create / Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "pacific-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = Tokenizer(num_words=len(word_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "weighted-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./SavedModels/BLSTM_tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-opinion",
   "metadata": {},
   "source": [
    "## 7.3. Tokenize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "stock-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "incident-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "convinced-premises",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205208"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index for each word in tokenizer\n",
    "len(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-azerbaijan",
   "metadata": {},
   "source": [
    "## 7.4. Convert training data to tokenized sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "funky-olive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'whole bodi feel itchi like fire'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "unlimited-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq = tokenizer.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "classical-nelson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[215, 6516, 323, 43, 2, 1144, 2019, 24001, 606, 3, 79, 76, 549]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_seq[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-action",
   "metadata": {},
   "source": [
    "## 7.5. Padding training sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "placed-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_seq_length, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "maritime-pontiac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  215,  6516,   323,    43,     2,  1144,  2019, 24001,   606,\n",
       "           3,    79,    76,   549,     0,     0,     0,     0,     0,\n",
       "           0,     0], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-publication",
   "metadata": {},
   "source": [
    "## 7.6. Performing tokenization and padding for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "unusual-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "loose-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_seq_length, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-submission",
   "metadata": {},
   "source": [
    "## 7.7. Understanding training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "communist-investing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[48,\n",
       " 287,\n",
       " 1034,\n",
       " 544,\n",
       " 985,\n",
       " 2194,\n",
       " 978,\n",
       " 985,\n",
       " 563,\n",
       " 543,\n",
       " 755,\n",
       " 469,\n",
       " 37,\n",
       " 22,\n",
       " 63,\n",
       " 1,\n",
       " 4865]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "simple-refrigerator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  48,  287, 1034,  544,  985, 2194,  978,  985,  563,  543,  755,\n",
       "        469,   37,   22,   63,    1, 4865,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "arbitrary-skating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17005, 1608, 884, 312, 57, 1587, 375, 37, 1046, 16, 875, 63, 2273]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "governing-terrain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17005,  1608,   884,   312,    57,  1587,   375,    37,  1046,\n",
       "          16,   875,    63,  2273,     0,     0,     0,     0,     0,\n",
       "           0,     0], dtype=int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "changing-bishop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1273563, 20)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "tamil-charm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318391, 20)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "determined-cleaners",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1273563,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "military-reputation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318391,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-signal",
   "metadata": {},
   "source": [
    "## 7.8 Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Maps each word to a finite vector\n",
    "model.add(Embedding(len(word_count), 20, input_length=max_seq_length))\n",
    "\n",
    "model.add(LSTM(32, dropout=0.1))\n",
    "\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0003)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_pad, y_train, epochs=1, validation_data=(X_test_pad, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-tomorrow",
   "metadata": {},
   "source": [
    "# 7.9. Training the model (GloVe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "interested-doctrine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('./SavedModels/glove.6B/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ignored-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index)+1, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "smaller-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Maps each word to a finite vector\n",
    "\n",
    "model.add(Embedding(len(word_index)+1, 100, weights=[embedding_matrix], input_length=max_seq_length, trainable=False))\n",
    "\n",
    "# model.add(Bidirectional(LSTM(64, dropout = 0.2, return_sequences = True)))\n",
    "\n",
    "model.add(LSTM(64, dropout = 0.2))\n",
    "\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "chief-chocolate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "39799/39799 [==============================] - 370s 9ms/step - loss: 0.5772 - accuracy: 0.6902 - val_loss: 0.5203 - val_accuracy: 0.7400\n",
      "Epoch 2/3\n",
      "39799/39799 [==============================] - 369s 9ms/step - loss: 0.5320 - accuracy: 0.7297 - val_loss: 0.5103 - val_accuracy: 0.7476\n",
      "Epoch 3/3\n",
      "39799/39799 [==============================] - 375s 9ms/step - loss: 0.5210 - accuracy: 0.7383 - val_loss: 0.5032 - val_accuracy: 0.7520\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_pad, y_train, epochs=3, validation_data=(X_test_pad, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "stone-commons",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 20, 100)           20520900  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 20,563,205\n",
      "Trainable params: 42,305\n",
      "Non-trainable params: 20,520,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fluid-detail",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./SavedModels/LSTM_GloVe_train_73_83_val_75_2_test_?_acc_epoch_3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-hudson",
   "metadata": {},
   "source": [
    "# 7.10 Word2Vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "widespread-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_train = list(map(lambda x: x.split(),list(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "included-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = gensim.models.Word2Vec(word2vec_train, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "internal-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(word2vec.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "polyphonic-problem",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(word2vec.wv.vectors, list(y)[:n//2] + list(y)[-n//2-1000:-1000],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "caring-latino",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31127, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "every-veteran",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-9e40d9aa6a07>:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  weights = word2vec.wv.syn0\n"
     ]
    }
   ],
   "source": [
    "weights = word2vec.wv.syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "general-moscow",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size, embedding_size = weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "exposed-compromise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38909, 100)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size, embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "renewable-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(38909, 100, weights=[weights], input_length=100, trainable=False))\n",
    "\n",
    "model.add(LSTM(100, dropout = 0.2))\n",
    "\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "marine-thompson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 100)          3890900   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 3,971,401\n",
      "Trainable params: 80,501\n",
      "Non-trainable params: 3,890,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cutting-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-combat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "973/973 [==============================] - 56s 58ms/step - loss: 0.5544 - accuracy: 0.6912 - val_loss: 0.5484 - val_accuracy: 0.6922\n",
      "Epoch 2/10\n",
      "973/973 [==============================] - 57s 59ms/step - loss: 0.5519 - accuracy: 0.6917 - val_loss: 0.5409 - val_accuracy: 0.7014\n",
      "Epoch 3/10\n",
      "973/973 [==============================] - 59s 61ms/step - loss: 0.5463 - accuracy: 0.7005 - val_loss: 0.5405 - val_accuracy: 0.6998\n",
      "Epoch 4/10\n",
      "973/973 [==============================] - 62s 64ms/step - loss: 0.5387 - accuracy: 0.7034 - val_loss: 0.5257 - val_accuracy: 0.7168\n",
      "Epoch 5/10\n",
      "973/973 [==============================] - 63s 65ms/step - loss: 0.5388 - accuracy: 0.7057 - val_loss: 0.5423 - val_accuracy: 0.7065\n",
      "Epoch 6/10\n",
      "973/973 [==============================] - 59s 60ms/step - loss: 0.5307 - accuracy: 0.7137 - val_loss: 0.5204 - val_accuracy: 0.7235\n",
      "Epoch 7/10\n",
      "973/973 [==============================] - 58s 60ms/step - loss: 0.5202 - accuracy: 0.7226 - val_loss: 0.5127 - val_accuracy: 0.7291\n",
      "Epoch 8/10\n",
      "973/973 [==============================] - 61s 62ms/step - loss: 0.5146 - accuracy: 0.7262 - val_loss: 0.5119 - val_accuracy: 0.7321\n",
      "Epoch 9/10\n",
      "410/973 [===========>..................] - ETA: 36s - loss: 0.5172 - accuracy: 0.7293"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train+10, y_train, epochs=10, validation_data=(X_test+10, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-shell",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-peter",
   "metadata": {},
   "source": [
    "# 8. Evaluating model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-disco",
   "metadata": {},
   "source": [
    "## 8.1. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unique-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./SavedModels/LSTM_GloVe_train_73_83_val_75_2_test_?_acc_epoch_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "consolidated-intervention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 20, 100)           20520900  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 20,563,205\n",
      "Trainable params: 42,305\n",
      "Non-trainable params: 20,520,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-priest",
   "metadata": {},
   "source": [
    "## 8.2. Create test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bottom-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/cleaned_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "mysterious-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.concat([test_df[test_df.sentiment != 0][:100000], test_df[test_df.sentiment == 0][:100000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mental-motorcycle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>Porter_Stem</th>\n",
       "      <th>Snowball_Stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>aww bummer shoulda got david carr third day</td>\n",
       "      <td>aww bummer shoulda got david carr third day</td>\n",
       "      <td>aww bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset cannot update facebook texting might cry...</td>\n",
       "      <td>upset can not updat facebook text might cri re...</td>\n",
       "      <td>upset can not updat facebook text might cri re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>dived many times ball managed save rest go bounds</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>behaving im mad cannot see</td>\n",
       "      <td>behav im mad can not see</td>\n",
       "      <td>behav im mad can not see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1          0  is upset that he can't update his Facebook by ...   \n",
       "2          0  @Kenichan I dived many times for the ball. Man...   \n",
       "3          0    my whole body feels itchy and like its on fire    \n",
       "4          0  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                       cleaned_tweet  \\\n",
       "0        aww bummer shoulda got david carr third day   \n",
       "1  upset cannot update facebook texting might cry...   \n",
       "2  dived many times ball managed save rest go bounds   \n",
       "3                   whole body feels itchy like fire   \n",
       "4                         behaving im mad cannot see   \n",
       "\n",
       "                                         Porter_Stem  \\\n",
       "0        aww bummer shoulda got david carr third day   \n",
       "1  upset can not updat facebook text might cri re...   \n",
       "2       dive mani time ball manag save rest go bound   \n",
       "3                    whole bodi feel itchi like fire   \n",
       "4                           behav im mad can not see   \n",
       "\n",
       "                                       Snowball_Stem  \n",
       "0        aww bummer shoulda got david carr third day  \n",
       "1  upset can not updat facebook text might cri re...  \n",
       "2       dive mani time ball manag save rest go bound  \n",
       "3                    whole bodi feel itchi like fire  \n",
       "4                           behav im mad can not see  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dominican-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[['sentiment', 'Snowball_Stem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "theoretical-necessity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Snowball_Stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>aww bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>upset can not updat facebook text might cri re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>behav im mad can not see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                      Snowball_Stem\n",
       "0          0        aww bummer shoulda got david carr third day\n",
       "1          0  upset can not updat facebook text might cri re...\n",
       "2          0       dive mani time ball manag save rest go bound\n",
       "3          0                    whole bodi feel itchi like fire\n",
       "4          0                           behav im mad can not see"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-willow",
   "metadata": {},
   "source": [
    "## 8.3. Drop rows with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "better-colleague",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment           0\n",
       "Snowball_Stem    8046\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "indie-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "supreme-folks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment        0\n",
       "Snowball_Stem    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-chemical",
   "metadata": {},
   "source": [
    "## 8.4. Tokenization and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "latin-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet = test_df['Snowball_Stem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sunrise-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "after-demonstration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          aww bummer shoulda got david carr third day\n",
       "1    upset can not updat facebook text might cri re...\n",
       "2         dive mani time ball manag save rest go bound\n",
       "3                      whole bodi feel itchi like fire\n",
       "4                             behav im mad can not see\n",
       "Name: Snowball_Stem, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "streaming-nebraska",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sweet-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet_seq = tokenizer.texts_to_sequences(test_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "signal-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet_pad = pad_sequences(test_tweet_seq, maxlen=max_seq_length, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "tough-brighton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 100, 1017, 3041,   10,  696, 6252, 1615,    3,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweet_pad[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-matter",
   "metadata": {},
   "source": [
    "## 8.5. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "relative-irrigation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2897/49749 [>.............................] - ETA: 1:57 - loss: 0.6562 - accuracy: 0.6210"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ee5f47825593>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tweet_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_tweet_pad, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "signal-filter",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-fa8cef49474b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss on test set:\", loss)\n",
    "print(\"Accuracy achieve on test set:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-visibility",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-dodge",
   "metadata": {},
   "source": [
    "# 9. Save model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./SavedModels/LSTM_train_75_val_78_test_79_acc.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./SavedModels/LSTM_tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
