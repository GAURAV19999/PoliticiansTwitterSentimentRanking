{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expanded-default",
   "metadata": {},
   "source": [
    "# SVM and Naive Bayes model for classification of tweet sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-damage",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-participation",
   "metadata": {},
   "source": [
    "# 1. Installs and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-cursor",
   "metadata": {},
   "source": [
    "## 1.1. Install all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "diverse-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment line below to install all required libraries\n",
    "# !pip3 install -r ../requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-storage",
   "metadata": {},
   "source": [
    "## 1.2. Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "becoming-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-plate",
   "metadata": {},
   "source": [
    "# 2. Load cleaned tweets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compressed-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./cleaned_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abandoned-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(450)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-boundary",
   "metadata": {},
   "source": [
    "# 3. Drop text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cloudy-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['sentiment', 'Snowball_Stem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "soviet-copying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Snowball_Stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>awww that bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>upset cant updat facebook text might cri resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>behav im mad cant see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                      Snowball_Stem\n",
       "0          0  awww that bummer shoulda got david carr third day\n",
       "1          0  upset cant updat facebook text might cri resul...\n",
       "2          0       dive mani time ball manag save rest go bound\n",
       "3          0                    whole bodi feel itchi like fire\n",
       "4          0                              behav im mad cant see"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-fleet",
   "metadata": {},
   "source": [
    "# 4. Drop rows with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "competent-sensitivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment           0\n",
       "Snowball_Stem    7661\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "compressed-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "defined-minimum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment        0\n",
       "Snowball_Stem    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "composed-valuable",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df['Snowball_Stem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hydraulic-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eight-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rolled-uncle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1194254,), (398085,), (1194254,), (398085,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-thanks",
   "metadata": {},
   "source": [
    "# 5. Applying TFIDF Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ignored-calendar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = TfidfVectorizer()\n",
    "v1.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "focused-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = v1.transform(X_train)\n",
    "X1_test = v1.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-hurricane",
   "metadata": {},
   "source": [
    "# 6. Applying TFIDF Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sharp-thailand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(ngram_range=(2, 2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2 = TfidfVectorizer(ngram_range = (2, 2))\n",
    "v2.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "plain-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train = v2.transform(X_train)\n",
    "X2_test = v2.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-tattoo",
   "metadata": {},
   "source": [
    "# 7. TFIDF Unigram + Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "visible-payday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(ngram_range=(1, 2))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v3 = TfidfVectorizer(ngram_range = (1, 2))\n",
    "v3.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "entitled-desert",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train = v3.transform(X_train)\n",
    "X3_test = v3.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-portland",
   "metadata": {},
   "source": [
    "# Encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "swiss-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "y_train = Encoder.fit_transform(y_train)\n",
    "y_test = Encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-mediterranean",
   "metadata": {},
   "source": [
    "# Running naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "perceived-techno",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Naive1 = naive_bayes.MultinomialNB()\n",
    "Naive1.fit(X1_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "concerned-prompt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Naive2 = naive_bayes.MultinomialNB()\n",
    "Naive2.fit(X2_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sixth-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB1 = Naive1.predict(X1_test)\n",
    "NB2 = Naive2.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "synthetic-latvia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Unigram Accuracy Score ->  76.1231897710288\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Unigram Accuracy Score -> \",accuracy_score(NB1, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "light-ribbon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Bigram Accuracy Score ->  74.31302360048734\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Bigram Accuracy Score -> \",accuracy_score(NB2, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "statistical-apparatus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Naive3= naive_bayes.MultinomialNB()\n",
    "Naive3.fit(X3_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "tracked-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB3 = Naive3.predict(X3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "opened-moderator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Bigram Accuracy Score ->  78.26871145609606\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Bigram Accuracy Score -> \",accuracy_score(NB3, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-warren",
   "metadata": {},
   "source": [
    "# 5. Reduce dataframe size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "passing-clearance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(796018, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment != 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dying-cigarette",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(796321, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "entitled-firewall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment != 0][:200000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "flying-timber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 0][:200000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "annoying-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = pd.concat([df[df.sentiment != 0][:50000], df[df.sentiment == 0][:50000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "revised-cutting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "interested-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "intimate-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df['Snowball_Stem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "worthy-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "changed-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "initial-clinic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75000,), (25000,), (75000,), (25000,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-intro",
   "metadata": {},
   "source": [
    "# TFIDF on reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "incoming-casino",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1_train = v1.transform(X_train)\n",
    "# X1_test = v1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "wired-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X2_train = v2.transform(X_train)\n",
    "# X2_test = v2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "based-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train = v3.transform(X_train)\n",
    "X3_test = v3.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-drive",
   "metadata": {},
   "source": [
    "# Running SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "composite-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM = svm.SVC(C=1.0, kernel='linear', degree=1, gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "colored-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM.fit(X1_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "patient-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels on validation dataset\n",
    "# SVM1_predictions = SVM.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "executive-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use accuracy_score function to get the accuracy\n",
    "# print(\"SVM Accuracy Score -> \",accuracy_score(SVM1_predictions, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "weird-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM2 = svm.SVC(C=1.0, kernel='linear', degree=1, gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "classified-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM2.fit(X2_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "insured-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM2_predictions = SVM2.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "chicken-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"SVM Accuracy Score -> \",accuracy_score(SVM2_predictions, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "danish-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM3 = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "grand-replica",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM3.fit(X3_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "adjustable-nomination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  77.072\n"
     ]
    }
   ],
   "source": [
    "SVM3_pred = SVM3.predict(X3_test)\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(SVM3_pred, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-porcelain",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-stereo",
   "metadata": {},
   "source": [
    "# Saving the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "exterior-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    " import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ceramic-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_model_path = \"./SVM_UnigramBigram_75.pickle\"\n",
    " NB_model_path = \"./NB_UnigramBigram_78.pickle\"\n",
    " vectorizer_path =\"./UnigramBigram_vectorizer.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "competitive-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(Naive3, open(NB_model_path, 'wb'))\n",
    "pickle.dump(SVM3, open(SVM_model_path,'wb'))\n",
    "pickle.dump(v3, open(vectorizer_path, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
